{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pyreadr\n",
    "import geopandas as gpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output directory\n",
    "output_dir = r'C:\\Workspace\\VisionEval\\psrc_scripts\\survey_data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode_dict = {\n",
    "    1: 1,    # 01\tWalk\t81,288\t8.8\n",
    "    2: 2,    # 02\tBicycle\t8,034\t0.9\n",
    "    3: 3,    # 03\tCar\t396,931\t43.0\n",
    "    4: 3,    # 04\tSUV\t229,466\t24.8\n",
    "    5: 3,    # 05\tVan\t60,463\t6.5\n",
    "    6: 11,    # 06\tPickup truck\t108,303\t11.7\n",
    "    8: 10,    # 07\tGolf cart / Segway\t826\t0.1\n",
    "    9: 97    # 08\tMotorcycle / Moped\t2,088\t0.2\n",
    "        # 09\tRV (motor home, ATV, snowmobile)\t814\t0.1\n",
    "        # 10\tSchool bus\t11,313\t1.2\n",
    "        # 11\tPublic or commuter bus\t6,616\t0.7\n",
    "        # 12\tParatransit / Dial-a-ride\t624\t0.1\n",
    "        # 13\tPrivate / Charter / Tour / Shuttle bus\t1,581\t0.2\n",
    "        # 14\tCity-to-city bus (Greyhound, Megabus)\t120\t0.0\n",
    "        # 15\tAmtrak / Commuter rail\t1,148\t0.1\n",
    "        # 16\tSubway / elevated / light rail / street car\t3,326\t0.4\n",
    "        # 17\tTaxi / limo (including Uber / Lyft)\t2,813\t0.3\n",
    "        # 18\tRental car (Including Zipcar / Car2Go)\t2,006\t0.2\n",
    "        # 19\tAirplane\t1,823\t0.2\n",
    "        # 20\tBoat / ferry / water taxi\t458\t0.0\n",
    "        # 97\tSomethi\n",
    "}\n",
    "\n",
    "purp_dict = {\n",
    "    0: 1,    # 01\tRegular home activities (chores, sleep)\t307,252\t33.3\n",
    "    1: 3,    # 02\tWork from home (paid)\t8,822\t1.0\n",
    "    2: 8,    # 03\tWork\t100,012\t10.8\n",
    "    3: 6,    # 04\tWork-related meeting / trip\t11,812\t1.3\n",
    "    4: 14,    # 05\tVolunteer activities (not paid)\t8,533\t0.9\n",
    "    5: 12,    # 06\tDrop off /pick up someone\t56,615\t6.1\n",
    "    6: 13,    # 07\tChange type of transportation\t9,536\t1.0\n",
    "    7: 17,    # 08\tAttend school as a student\t22,645\t2.5\n",
    "    10: 7    # 09\tAttend child care\t2,082\t0.2\n",
    "        # 10\tAttend adult care\t560\t0.1\n",
    "        # 11\tBuy goods (groceries, clothes, appliances, gas)\t132,851\t14.4\n",
    "        # 12\tBuy services (dry cleaners, banking, service a car, pet care)\t23,592\t2.6\n",
    "        # 13\tBuy meals (go out for a meal, snack, carry-out)\t72,391\t7.8\n",
    "        # 14\tOther general errands (post office, library)\t28,126\t3.0\n",
    "        # 15\tRecreational activities (visit parks, movies, bars, museums)\t31,394\t3.4\n",
    "        # 16\tExercise (go for a jog, walk, walk the dog, go to the gym)\t31,518\t3.4\n",
    "        # 17\tVisit friends or relatives\t36,869\t4.0\n",
    "        # 18\tHealth care visit (medical, dental, therapy)\t16,967\t1.8\n",
    "        # 19\tReligious or other community activities\t18,896\t2.0\n",
    "        # 97\tSomething else\n",
    "}\n",
    "\n",
    "hometype_map = {\n",
    "        # -7=Refused 16 11\n",
    "        # -8=Don't Know 18 5\n",
    "        1: 1,# 1=Detached single house 122\n",
    "        2: 2,# 2=Duplex 6\n",
    "        3: 4,# 3=Rowhouse or townhouse 6\n",
    "        4: 5,# 4=Apartment  condominium\n",
    "        5: 6,# 5=Mobile home or trailer 6\n",
    "        6: 91,# 6=Dorm room  fraternity or sorority house\n",
    "        9: 91# 91=Other\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Household"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daysim Survey location\n",
    "daysim_loc = r'R:\\e2projects_two\\SoundCast\\Inputs\\dev\\base_year\\2018\\survey'\n",
    "daysim_hh = pd.read_csv(os.path.join(daysim_loc,'_household.tsv'), delim_whitespace=True)\n",
    "daysim_person = pd.read_csv(os.path.join(daysim_loc,'_person.tsv'), delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NHTS survey files\n",
    "fname = r'C:\\Workspace\\VisionEval_build\\VisionEval\\sources\\modules\\VE2001NHTS\\data-raw\\Hh_df.Rda'\n",
    "nhts_hh = pyreadr.read_r(fname)['Hh_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ve_hh = pd.pivot_table(daysim_person, index='hhno', columns='pno', values='pagey', aggfunc='mean').reset_index()\n",
    "for i in range(1,15):\n",
    "    if i not in ve_hh.columns:\n",
    "        ve_hh['AGE_P'+str(i)] = -1\n",
    "    ve_hh.rename(columns={i: 'AGE_P'+str(i)}, inplace=True)\n",
    "ve_hh.rename(columns={'hhno': 'HOUSEID'}, inplace=True)\n",
    "\n",
    "ve_hh = ve_hh.merge(daysim_person, left_on='HOUSEID', right_on='hhno', how='left')\n",
    "ve_hh = ve_hh.merge(daysim_hh,  on='hhno', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'CENSUS_D':  household Census division\n",
    "# division 9; https://www2.census.gov/geo/pdfs/maps-data/maps/reference/us_regdiv.pdf\n",
    "ve_hh['CENSUS_D'] = 9\n",
    "\n",
    "# 'CENSUS_R': houeshold census region\n",
    "# region 4;\n",
    "ve_hh['CENSUS_R'] = 4\n",
    "\n",
    "# 'EXPFLHHN', HH Weight-100 percent completed - NATL\n",
    "# use hhexpfac?\n",
    "ve_hh['EXPFLHHN'] = ve_hh['hhexpfac'].copy()\n",
    "\n",
    "# 'EXPFLLHH',HH Weight-100 percent completed\n",
    "ve_hh['EXPFLLHH'] = ve_hh['hhexpfac'].copy()\n",
    "\n",
    "#  'FLGFINCM', Incomes of all HH members included?\n",
    "# Assume yes \n",
    "ve_hh['FLGFINCM'] = 1\n",
    "\n",
    "# 'HHC_MSA', MSA / CMSA code for HH\n",
    "# FIXME: there is an MSA code for bremerton/kitsap county that should be used in some cases\n",
    "# 42660: https://www.hud.gov/sites/documents/11-39MLATCH2.PDF\n",
    "ve_hh['HHC_MSA'] = 42660\n",
    "\n",
    "# 'HHNUMBIK', Number of full size bicycles in HH\n",
    "# FIXME: get this from the NHTS average for our area or some other source\n",
    "ve_hh['HHNUMBIK'] = 0\n",
    "\n",
    "# 'HHR_DRVR',Driver status of HH respondent  | 1 y, 2 n\n",
    "# FIXME: for now assume all respondents are drivers\n",
    "ve_hh['HHR_DRVR'] = 1\n",
    "\n",
    "# 'HHSIZE', Count of HH members\n",
    "ve_hh['HHSIZE'] = ve_hh['hhsize'].copy()\n",
    "\n",
    "# 'HHVEHCNT', Count of vehicles in HH\n",
    "ve_hh['HHVEHCNT'] = ve_hh['hhvehs'].copy()\n",
    "\n",
    "# 'HOMETYPE', Type of housing unit\n",
    "ve_hh['HOMETYPE'] = ve_hh['hrestype'].map(hometype_map)\n",
    "\n",
    "# 'MSAPOP', Number of persons residing in the MSA\n",
    "# Estimating 3.8 M in 2018?\n",
    "# FIXME: get the actual number and account for bremerton MSA\n",
    "ve_hh['MSAPOP'] = 3800000\n",
    "\n",
    "# MSACAT\n",
    "# 1=MSA of 1 million or more, with rail\n",
    "# 2=MSA of 1 million or more, and not in 1\n",
    "# 3=MSA less than 1 million\n",
    "# 4=Not in MSA (CMSA)\n",
    "ve_hh['MSACAT'] = 1\n",
    "\n",
    "# 'MSASIZE', MSA size; https://nhts.ornl.gov/tables09/CodebookPage.aspx?id=1257\n",
    "ve_hh['MSASIZE'] = 5\n",
    "\n",
    "# 'RAIL', Rail (subway) category. whether the household is located in a MSA with rail.\n",
    "ve_hh['RAIL'] = 1\n",
    "\n",
    "# 'URBAN', Household in urbanized area | Household's urban area classification, based on home address and 2014 TIGER/Line Shapefile\n",
    "# 1=In an Urban cluster\n",
    "# 2=In an urban area\n",
    "# 3=In an area surrounded by urban areas\n",
    "# 4=Not in urban area\n",
    "# FIXME: need to do this for each household?\n",
    "# Assume all urban for now\n",
    "ve_hh['URBAN'] = 1\n",
    "\n",
    "# 'URBRUR', Household in urban/rural area | 1 URBAN , 2 RURAL\n",
    "# We can get this from ElmerGeo definitions\n",
    "ve_hh['URBRUR'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 'CNTTDHH' \n",
    "# Sum of all travel period person trips. sum of all Travel Day person trips enumerated\n",
    "# (G12 through G14) by interviewed household members in useable households\n",
    "# Total trips, can be produced by aggregating the trips file\n",
    "tot_trips = daysim_trip.groupby('hhno').count()[['trexpfac']].reset_index()\n",
    "ve_hh = ve_hh.merge(tot_trips, on='hhno', how='left')\n",
    "ve_hh.rename(columns={'trexpfac': 'CNTTDHH'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'HHFAMINC', Total HH income last 12 months (category)\n",
    "ve_hh['HHFAMINC'] =pd.cut(ve_hh['hhincome'], bins=[-1,10000,15000,25000,35000,49000,75000,100000,125000,150000,200000,99999999999],\n",
    "                        labels=[1,2,3,4,5,6,7,8,9,10,11])\n",
    "\n",
    "# # 'HHINCTTL', Total income all HH members (category)\n",
    "ve_hh['HHINCTTL'] = ve_hh['HHFAMINC'].copy()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 'WRKCOUNT',Count of HH members with jobs\n",
    "ve_hh['WRKCOUNT'] = ve_hh['hhwkrs']\n",
    "\n",
    "\n",
    "# WKR_P1 - WKR_P14\n",
    "daysim_person['is_worker'] = 2\n",
    "daysim_person.loc[daysim_person['pwtyp'] > 0, 'is_worker'] = 1\n",
    "\n",
    "df = pd.pivot_table(daysim_person, index='hhno', columns='pno', values='is_worker', aggfunc='sum').reset_index()\n",
    "for i in range(1,15):\n",
    "    if i not in df.columns:\n",
    "        df['WKR_P'+str(i)] = -1\n",
    "    df.rename(columns={i: 'WKR_P'+str(i)}, inplace=True)\n",
    "\n",
    "ve_hh = ve_hh.merge(df, on='hhno', how='left')\n",
    "\n",
    "# 'DRVRCNT': drivers in household\n",
    "# FIXME: Get from Elmer\n",
    "# for now assume all people >= 16 are drivers\n",
    "df = daysim_person[daysim_person['pagey'] >= 16]\n",
    "df = df.groupby('hhno').count()[['psexpfac']].reset_index()\n",
    "df.rename(columns={'psexpfac': 'DRVRCNT'}, inplace=True)\n",
    "ve_hh = ve_hh.merge(df, on='hhno', how='left')\n",
    "\n",
    "# 'DRV_P1' - 'DRV_P14', driver status\n",
    "# 1 y, 2 n\n",
    "# Again, assuming all 16+ people are drivers\n",
    "daysim_person['is_driver'] = 2\n",
    "daysim_person.loc[daysim_person['pagey'] >= 16, 'is_driver'] = 1\n",
    "df = pd.pivot_table(daysim_person, index='hhno', columns='pno', values='is_driver', aggfunc='sum').reset_index()\n",
    "for i in range(1,15):\n",
    "    if i not in df.columns:\n",
    "        df['DRV_P'+str(i)] = -1\n",
    "    df.rename(columns={i: 'DRV_P'+str(i)}, inplace=True)\n",
    "    # ve_hh['DRV_P'+str(i)].replace(0,2, inplace=True)\n",
    "ve_hh = ve_hh.merge(df, on='hhno', how='left')\n",
    "\n",
    "# 'RATIO16V', Ratio - HH members (16+) to vehicles\n",
    "ve_hh['RATIO16V'] = ve_hh['DRVRCNT']/ve_hh['hhvehs']\n",
    "ve_hh['RATIO16V'] = ve_hh['RATIO16V'].replace(np.inf, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'HHR_AGE', Respondent age\n",
    "# Use oldest member of the household\n",
    "df = daysim_person.groupby('hhno').max()[['pagey']].reset_index()\n",
    "df.rename(columns={'pagey': 'HHR_AGE'}, inplace=True)\n",
    "ve_hh = ve_hh.merge(df, on='hhno', how='left')\n",
    "\n",
    "# 'HHR_RACE', Race of HH respondent\n",
    "# FIXME: \n",
    "ve_hh['HHR_RACE'] = 1\n",
    "\n",
    "# 'HHR_SEX', Gender of HH respondent\n",
    "# FIXME: change this if it matters for estimation?\n",
    "ve_hh['HHR_SEX'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'LIF_CYC', HH Life Cycle\n",
    "# FIXME: calculate this for the household\n",
    "ve_hh['LIF_CYC'] =-9\n",
    "\n",
    "# -9=Not Ascertained\t\n",
    "# 01=one adult, no children\t\n",
    "# 02=2+ adults, no children\t\n",
    "# 03=one adult, youngest child 0-5\t\n",
    "# 04=2+ adults, youngest child 0-5\t\n",
    "# 05=one adult, youngest child 6-15\t\n",
    "# 06=2+ adults, youngest child 6-15\t\n",
    "# 07=one adult, youngest child 16-21\t\n",
    "# 08=2+ adults, youngest child 16-21\t\n",
    "# 09=one adult, retired, no children\t\n",
    "# 10=2+ adults, retired, no children\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve_hh['RATIO16V'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['aparks', 'empedu_p', 'empfoo_p', 'empgov_p', 'empind_p', 'empmed_p',\n",
       "       'empofc_p', 'empoth_p', 'empret_p', 'emprsc_p', 'empsvc_p', 'emptot_p',\n",
       "       'hh_p', 'lutype_p', 'mfunits', 'nparks', 'parcelid', 'parkdy_p',\n",
       "       'parkhr_p', 'ppricdyp', 'pprichrp', 'sfunits', 'sqft_p', 'stugrd_p',\n",
       "       'stuhgh_p', 'stuuni_p', 'taz_p', 'xcoord_p', 'ycoord_p'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_lu = pd.read_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\dev\\landuse\\2018\\v3_RTP\\parcels_urbansim.txt', delim_whitespace=True)\n",
    "df_lu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 691,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each TAZ? \n",
    "df = df_lu.groupby('taz_p').sum()[['hh_p']]\n",
    "df2 = df_lu.groupby('taz_p').sum()[['sqft_p']]\n",
    "df2['sq_mile'] = df2['sqft_p']/(5280**2)\n",
    "df = df.merge(df2,  left_index=True, right_index=True)\n",
    "df['HBHRESDN'] = df['hh_p']/df['sq_mile']\n",
    "df['HBHRESDN'].max()\n",
    "\n",
    "# Load parcel geography lookup table\n",
    "parcel_lookup = pd.read_csv(r'R:\\e2projects_two\\SoundCast\\Inputs\\db_inputs\\parcel_2018_geography.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lu = df_lu.merge(parcel_lookup, left_on='parcelid', right_on='ParcelID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_lu.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# The following data must be provided by land use data\n",
    "# 'HBHRESDN', Housing units per sq mile - Block group. Housing units density in units per square mile provided by Claritas\n",
    "\n",
    "# 'HBHUR', Urban / Rural indicator - Block group\n",
    "# Fixme: get this definition from land use\n",
    "ve_hh['HBHUR'] = 'U'\n",
    "\n",
    "# 'HBPPOPDN', Population per sq mile - Block group\n",
    "\n",
    "# 'HTEEMPDN',Workers per square mile living in Tract\n",
    "\n",
    "# 'HTHRESDN', Housing units per sq mile - Tract level\n",
    "# 'HTHUR', Urban / Rural indicator - Tract level\n",
    "ve_hh['HTHUR'] = 'U'\n",
    "# 'HTPPOPDN', Population per sq mile - Tract level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ve_hh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For now just set these all at 1\n",
    "ve_hh[['HBHRESDN', 'HBPPOPDN', 'HTEEMPDN', 'HTHRESDN','HTPPOPDN']] = 3000\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Modeller\\.conda\\envs\\summary\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "# Floats\n",
    "# \n",
    "float_cols = ['EXPFLHHN','EXPFLLHH','HBHUR','HTHUR','HHFAMINC','HHINCTTL','CENSUS_D','CENSUS_R']\n",
    "ve_hh[nhts_hh.columns.drop(float_cols)] = ve_hh[nhts_hh.columns.drop(float_cols)].fillna(-1).astype('int')\n",
    "df = ve_hh[nhts_hh.columns]\n",
    "\n",
    "df['HOUSEID'] = df['HOUSEID'].astype('str')\n",
    "pyreadr.write_rdata(output_dir + '\\\\Hh_df.Rda', df, df_name=\"Hh_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        1\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "11925    1\n",
       "11926    1\n",
       "11927    1\n",
       "11928    1\n",
       "11929    1\n",
       "Name: HBHUR, Length: 11930, dtype: int64"
      ]
     },
     "execution_count": 534,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ve_hh['HBHUR']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Persons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NHTS survey files\n",
    "fname = r'C:\\Workspace\\VisionEval_build\\VisionEval\\sources\\modules\\VE2001NHTS\\data-raw\\Per_df.Rda'\n",
    "nhts_person = pyreadr.read_r(fname)['Per_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOUSEID\t\n",
    "daysim_person['HOUSEID'] = daysim_person['hhno'].astype('str')\n",
    "# PERSONID\t\n",
    "daysim_person['PERSONID'] = daysim_person['pno'].astype('str')\n",
    "\n",
    "# COMMDRVR\tPerson is a commercial driver\n",
    "# FIXME: get this from Elmer\n",
    "# Assuming no for all persons for now\n",
    "daysim_person['COMMDRVR'] = 2\n",
    "\n",
    "# NBIKETRP\tNumber of bike trips in past week\n",
    "# FIXME: get this from Elmer\n",
    "# For now extrapolate based on daysim data; if they rode a bike on the current day, assume 3 otherwise 0\n",
    "daysim_trip['PERSONID']  = daysim_trip['hhno'].astype('str') + daysim_trip['pno'].astype('str')\n",
    "bike_trips = daysim_trip[daysim_trip['mode'] == 2]\n",
    "bike_trips = bike_trips.groupby('PERSONID').count()[['trexpfac']].reset_index()\n",
    "bike_trips.rename(columns={'trexpfac': 'NBIKETRP'}, inplace=True)\n",
    "daysim_person = daysim_person.merge(bike_trips, how='left', on='PERSONID')\n",
    "daysim_person['NBIKETRP'].fillna(0, inplace=True)\n",
    "daysim_person['NBIKETRP']= daysim_person['NBIKETRP']*4     # Average for the week\n",
    "\n",
    "# NWALKTRP\tNumber of walk trips in past week\n",
    "# FIXME: get this from Elmer\n",
    "walk_trips = daysim_trip[daysim_trip['mode'] == 1]\n",
    "walk_trips = walk_trips.groupby('PERSONID').count()[['trexpfac']].reset_index()\n",
    "walk_trips.rename(columns={'trexpfac': 'NWALKTRP'}, inplace=True)\n",
    "daysim_person = daysim_person.merge(walk_trips, how='left', on='PERSONID')\n",
    "daysim_person['NWALKTRP'].fillna(0, inplace=True)\n",
    "daysim_person['NWALKTRP']= daysim_person['NWALKTRP']*4    # Average for the week\n",
    "\n",
    "# WRKDRIVE\tJob requires driving a motor vehicle\n",
    "# FIXME: get this from Elmer\n",
    "# Assuming no for all persons for now\n",
    "daysim_person['WRKDRIVE'] = 2\n",
    "\n",
    "# WORKER\tPerson has job (1=yes, 0=no)\n",
    "daysim_person['WORKER'] = 0\n",
    "daysim_person.loc[daysim_person['pwtyp'] > 0, 'WORKER'] = 1\n",
    "\n",
    "# DTGAS\t\n",
    "# Not sure of the source of this field; in original data it's an integer\n",
    "# potentially PRICE field in NHTS codebook; influence of gas price on choices\n",
    "daysim_person['DTGAS'] = 3\n",
    "\n",
    "# DISTTOWK\tDistance to work in miles\n",
    "daysim_person['DISTTOWK'] = daysim_person['pwaudist'].copy()\n",
    "\n",
    "# DRIVER\tDriver status (1=driver, 0=non-driver)\n",
    "daysim_person['DRIVER'] = 2\n",
    "daysim_person.loc[daysim_person['pagey'] >= 16, 'DRIVER'] = 1\n",
    "\n",
    "# R_AGE\tRespondent age\n",
    "daysim_person['R_AGE'] = daysim_person['pagey'].copy()\n",
    "\n",
    "# R_SEX\tR_sex\n",
    "# Male 1; female 2\n",
    "daysim_person['R_SEX'] = daysim_person['pgend'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# USEPUBTR\tUsed public transit on travel day\n",
    "# FIXME: lookup from trip file\n",
    "daysim_trip['PERSONID'] = daysim_trip['hhno'].astype('str')+daysim_trip['pno'].astype('str')\n",
    "df = daysim_trip[daysim_trip['mode'] == 6]\n",
    "daysim_person['USEPUBTR'] = 2\n",
    "daysim_person.loc[daysim_person['PERSONID'].isin(df['PERSONID'].unique()),'USEPUBTR'] = 1\n",
    "\n",
    "# WRKTRANS\tTransportation mode to work last week\n",
    "# FIXME: Get usual commute mode from Elmer\n",
    "df = daysim_trip[daysim_trip['dpurp'] == 1]\n",
    "df = df.groupby('PERSONID').first()[['mode']].reset_index()\n",
    "df.rename(columns={'mode': 'WRKTRANS'}, inplace=True)\n",
    "daysim_person = daysim_person.merge(df, on='PERSONID', how='left')\n",
    "daysim_person['WRKTRANS'] = daysim_person['WRKTRANS'].map(mode_dict)\n",
    "daysim_person['WRKTRANS'].fillna(-1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Modeller\\.conda\\envs\\summary\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "daysim_person[nhts_person.columns.drop('DISTTOWK')] = daysim_person[nhts_person.columns.drop('DISTTOWK')].astype('int')\n",
    "df = daysim_person[nhts_person.columns]\n",
    "df['HOUSEID'] = df['HOUSEID'].astype('str')\n",
    "pyreadr.write_rdata(output_dir + '\\\\Per_df.Rda', df, df_name=\"Per_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HOUSEID</th>\n",
       "      <th>PERSONID</th>\n",
       "      <th>COMMDRVR</th>\n",
       "      <th>NBIKETRP</th>\n",
       "      <th>NWALKTRP</th>\n",
       "      <th>USEPUBTR</th>\n",
       "      <th>WRKDRIVE</th>\n",
       "      <th>WRKTRANS</th>\n",
       "      <th>WORKER</th>\n",
       "      <th>DTGAS</th>\n",
       "      <th>DISTTOWK</th>\n",
       "      <th>DRIVER</th>\n",
       "      <th>R_AGE</th>\n",
       "      <th>R_SEX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17100005</td>\n",
       "      <td>171000051</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17100005</td>\n",
       "      <td>171000052</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>17100024</td>\n",
       "      <td>171000241</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17100024</td>\n",
       "      <td>171000242</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.37</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17100024</td>\n",
       "      <td>171000243</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11925</th>\n",
       "      <td>192018397</td>\n",
       "      <td>1920183971</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11926</th>\n",
       "      <td>192018397</td>\n",
       "      <td>1920183972</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.24</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11927</th>\n",
       "      <td>192018425</td>\n",
       "      <td>1920184252</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>11.38</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11928</th>\n",
       "      <td>192018425</td>\n",
       "      <td>1920184251</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11929</th>\n",
       "      <td>192018425</td>\n",
       "      <td>1920184253</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11930 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         HOUSEID    PERSONID  COMMDRVR  NBIKETRP  NWALKTRP  USEPUBTR  \\\n",
       "0       17100005   171000051         2         0         0         2   \n",
       "1       17100005   171000052         2         0         0         2   \n",
       "2       17100024   171000241         2         8        16         2   \n",
       "3       17100024   171000242         2         0         4         1   \n",
       "4       17100024   171000243         2         4         0         2   \n",
       "...          ...         ...       ...       ...       ...       ...   \n",
       "11925  192018397  1920183971         2         0         8         2   \n",
       "11926  192018397  1920183972         2         0         0         2   \n",
       "11927  192018425  1920184252         2         0         8         2   \n",
       "11928  192018425  1920184251         2         0         0         2   \n",
       "11929  192018425  1920184253         2         0         0         2   \n",
       "\n",
       "       WRKDRIVE  WRKTRANS  WORKER  DTGAS  DISTTOWK  DRIVER  R_AGE  R_SEX  \n",
       "0             2        -1       0      3     -1.00       1     60      2  \n",
       "1             2        -1       0      3     -1.00       1     70      1  \n",
       "2             2         1       1      3      0.14       1     30      9  \n",
       "3             2         1       1      3      1.37       1     30      2  \n",
       "4             2        -1       0      3     -1.00       2      2      9  \n",
       "...         ...       ...     ...    ...       ...     ...    ...    ...  \n",
       "11925         2        -1       1      3     -1.00       1     30      1  \n",
       "11926         2         3       1      3      4.24       1     30      2  \n",
       "11927         2         3       1      3     11.38       1     30      1  \n",
       "11928         2        -1       1      3     -1.00       1     30      2  \n",
       "11929         2        -1       0      3     -1.00       2      2      2  \n",
       "\n",
       "[11930 rows x 14 columns]"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "daysim_tour = pd.read_csv(os.path.join(daysim_loc,'_tour.tsv'), delim_whitespace=True)\n",
    "daysim_person = pd.read_csv(os.path.join(daysim_loc,'_person.tsv'), delim_whitespace=True)\n",
    "\n",
    "# Load NHTS survey files\n",
    "fname = r'C:\\Workspace\\VisionEval_build\\VisionEval\\sources\\modules\\VE2001NHTS\\data-raw\\ToursByHh_df.Rda'\n",
    "nhts_tour = pyreadr.read_r(fname)['ToursByHh_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daysim_tour[['tripsh1','tripsh2']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Houseid\tUnique household ID\n",
    "Distance\tTotal distance in miles of the tour\n",
    "TravelTime\tTotal time in minutes spent traveling on the tour\n",
    "DwellTime\tTotal time in minutes spent at activities on the tour\n",
    "StartHome\tLogical identifying if the tour started at home\n",
    "EndHome\tLogical identifying if the tour ended at home\n",
    "Trips\tNumber of trips in the tour\n",
    "Persons\tNumber of persons on the tour\n",
    "Vehid\tUnique ID for vehicle in household\n",
    "Trptrans\tMode of transportation (see 2001 NHTS codebook for TRPTRANS)\n",
    "Vehtype\tType of vehicle used (see 2001 NHTS codebook for VEHTYPE)\n",
    "HhVehUsed\tWhether household vehicle used (1=yes, 2=no)\n",
    "Whyto\tString contenating successive activity codes at trip end (see 2001 NHTS codebook for WHYTO)\n",
    "Disttowk\tDistance from home to work for the person on the tour who works farthest from home -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Houseid\tUnique household ID\n",
    "daysim_tour['Houseid'] = daysim_tour['hhno'].astype('str')\n",
    "\n",
    "# Distance\tTotal distance in miles of the tour\n",
    "daysim_tour['Distance'] = (daysim_tour['d']/100.0).copy()\n",
    "\n",
    "# TravelTime\tTotal time in minutes spent traveling on the tour\n",
    "daysim_tour['TravelTime'] = (daysim_tour['t']/100.0).copy()\n",
    "\n",
    "# DwellTime\tTotal time in minutes spent at activities on the tour\n",
    "daysim_tour['DwellTime'] = daysim_tour['tarorig'] - daysim_tour['tlvorig']\n",
    "\n",
    "# StartHome\n",
    "daysim_tour[['StartHome','EndHome']] = False\n",
    "daysim_tour.loc[daysim_tour['pdpurp'] != 0, 'StartHome'] = True\n",
    "\n",
    "# EndHome\n",
    "daysim_tour.loc[daysim_tour['pdpurp'] == 0, 'EndHome'] = True\n",
    "\n",
    "# Trips\n",
    "daysim_tour['Trips'] = daysim_tour[['tripsh1','tripsh2']].sum(axis=1)\n",
    "\n",
    "# Vehid\n",
    "# FIXME use Elmer to get vehicle ID based on mode_1 values\n",
    "# 3 - 12 are various household vehicles\n",
    "daysim_tour['Vehid'] = 1\n",
    "\n",
    "# Trptrans\n",
    "daysim_tour['Trptrans'] = daysim_tour['tmodetp'].map(mode_dict)\n",
    "\n",
    "# Vehtype\tType of vehicle used (see 2001 NHTS codebook for VEHTYPE)\n",
    "# FIXME: look this up from Elmer\n",
    "daysim_tour['Vehtype'] = 1\n",
    "# 01=Car\n",
    "# 02=Van\n",
    "# 03=SUV\n",
    "# 04=Pickup truck\n",
    "# 05=Other truck\n",
    "# 06=RV\n",
    "# 07=Motorcycle\n",
    "# 91=Other\n",
    "\n",
    "# Persons\n",
    "# Fixme look up from Elmer\n",
    "daysim_tour['Persons'] = 1\n",
    "\n",
    "# HhVehUsed\tWhether household vehicle used (1=yes, 2=no)\n",
    "# FIXME: look this up from Elmer\n",
    "daysim_tour['HhVehUsed'] = 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Disttowk\tDistance from home to work for the person on the tour who works farthest from home\n",
    "daysim_tour['PERSONID'] = daysim_tour['pno']\n",
    "daysim_tour = daysim_tour.merge(daysim_person[['hhno','pno','pwaudist']], on=['hhno','pno'], how='left')\n",
    "daysim_tour['Disttowk'] = daysim_tour['pwaudist'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Modeller\\.conda\\envs\\summary\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3166: DtypeWarning: Columns (22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "daysim_trip = pd.read_csv(os.path.join(daysim_loc,'_trip.tsv'), delim_whitespace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daysim_tour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whyto\tString contenating successive activity codes at trip end (see 2001 NHTS codebook for WHYTO)\n",
    "\n",
    "# Get concatenation from trips\n",
    "\n",
    "\n",
    "\n",
    "daysim_trip['Whyto'] = daysim_trip['dpurp'].map(purp_dict).astype('str')\n",
    "df = daysim_trip.groupby(['hhno','pno','day','tour']).agg({'Whyto': lambda x: '-'.join(set(x))}).reset_index()\n",
    "daysim_tour = daysim_tour.merge(df, on=['hhno','pno','day','tour'], how='left')\n",
    "# -7=Refused 64 19,794,097\n",
    "# -8=Don't Know 259 132,632,045\n",
    "# -9=Not Ascertained 126 44,702,675\n",
    "# 01=Home 219,701 137,689,298,480\n",
    "# 11=Go to work 47,975 29,451,746,910\n",
    "# 12=Return to work 11,141 7,613,650,347\n",
    "# 13=Attend business meeting/trip 1,363 871,580,135\n",
    "# 14=Other work related 11,719 7,907,627,500\n",
    "# 20=School/religious activity 4,019 2,042,102,857\n",
    "# 21=Go to school as student 18,557 12,580,912,637\n",
    "# 22=Go to religious activity 9,925 6,748,570,907\n",
    "# 23=Go to library: school related 868 611,747,616\n",
    "# 24=OS - Day care 2,487 1,946,703,725\n",
    "# 30=Medical/dental services 9,241 5,591,347,518\n",
    "# 40=Shopping/errands 18,445 9,664,073,513\n",
    "# 41=Buy goods: groceries/clothing/hardware store 72,946 45,833,056,825\n",
    "# 42=Buy services: video rentals/dry cleaner/post office/car service/bank\n",
    "# 43=Buy gas 9,536 6,527,025,830\n",
    "# 50=Social/recreational 7,042 3,361,065,902\n",
    "# 51=Go to gym/exercise/play sports 19,898 12,826,376,945\n",
    "# 52=Rest or relaxation/vacation 2,916 1,867,012,600\n",
    "# 53=Visit friends/relatives 30,680 20,272,463,086\n",
    "# 54=Go out/hang out: entertainment/theater/sports event/go to bar\n",
    "# 55=Visit public place: historical site/museum/park/library 2,775 1,667,634,692\n",
    "# 60=Family personal business/obligations 9,990 6,123,424,057\n",
    "# 61=Use professional services: attorney/accountant 1,360 952,077,862\n",
    "# 62=Attend funeral/wedding 1,133 733,967,929\n",
    "# 63=Use personal services: grooming/haircut/nails 2,384 1,530,137,567\n",
    "# 64=Pet care: walk the dog/vet visits 2,689 1,681,188,074\n",
    "# 65=Attend meeting: PTA/home owners association/local government 3,139 1,866,480,387\n",
    "# 70=Transport someone 801 466,247,452\n",
    "# 71=Pick up someone 17,431 11,382,208,501\n",
    "# 72=Take and wait 3,910 3,163,771,957\n",
    "# 73=Drop someone off 19,085 12,587,299,015\n",
    "# 80=Meals 3,999 1,383,289,688\n",
    "# 81=Social event 3,201 2,168,662,259\n",
    "# 82=Get/eat meal 30,313 21,394,703,354\n",
    "# 83=Coffee/ice cream/snacks 3,844 2,611,957,719\n",
    "# 91=Other reason"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {},
   "outputs": [],
   "source": [
    "# daysim_tour['Whyto']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daysim_tour[nhts_tour.columns]\n",
    "pyreadr.write_rdata(output_dir + '\\\\ToursByHh_df.Rda', df, df_name=\"ToursByHh_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load NHTS survey files\n",
    "fname = r'C:\\Workspace\\VisionEval_build\\VisionEval\\sources\\modules\\VE2001NHTS\\data-raw\\Dt_df.Rda'\n",
    "nhts_trip = pyreadr.read_r(fname)['Dt_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HOUSEID', 'PERSONID', 'VEHID'], dtype='object')"
      ]
     },
     "execution_count": 708,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhts_trip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['hhno', 'pno', 'day', 'tour', 'half', 'tseg', 'tsvid', 'opurp', 'dpurp',\n",
       "       'oadtyp', 'dadtyp', 'opcl', 'dpcl', 'otaz', 'dtaz', 'mode', 'pathtype',\n",
       "       'dorp', 'deptm', 'arrtm', 'endacttm', 'trexpfac', 'id', 'travtime',\n",
       "       'travcost', 'travdist', 'sov_ff_time', 'Whyto'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "daysim_trip.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 710,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'HOUSEID', \n",
    "daysim_trip['HOUSEID'] = daysim_trip['hhno'].astype('str')\n",
    "# 'TDCASEID', \n",
    "daysim_trip['TDCASEID'] = range(1,len(daysim_trip)+1)\n",
    "\n",
    "# 'VEHID', \n",
    "# FIXME: see if we can get this data from Elmer\n",
    "daysim_trip['VEHID'] = 1\n",
    "\n",
    "# 'VEHUSED', \n",
    "daysim_trip['VEHUSED'] = 2\n",
    "daysim_trip.loc[daysim_trip['mode'].isin([3,4,5]), 'VEHUSED'] = 1\n",
    "\n",
    "# 'TRPHHVEH', \n",
    "# assuming all vehicles used are hh vehicles\n",
    "daysim_trip['TRPHHVEH'] = daysim_trip['VEHID'].copy()\n",
    "\n",
    "# 'PERSONID',\n",
    "daysim_trip['PERSONID'] = daysim_trip['hhno'].astype('str')+daysim_trip['pno'].astype('str')\n",
    "\n",
    "# 'NUMONTRP', \n",
    "# FIXME: Get from Elmer\n",
    "daysim_trip['NUMONTRP'] = 1\n",
    "\n",
    "# 'TRPTRANS', \n",
    "daysim_trip['TRPTRANS'] = daysim_trip['mode'].map(mode_dict)\n",
    "\n",
    "# 'TRPMILES', \n",
    "daysim_trip['TRPMILES'] = daysim_trip['travdist'].copy()\n",
    "\n",
    "# 'TRVL_MIN', \n",
    "daysim_trip['TRVL_MIN'] = daysim_trip['travtime'].copy()\n",
    "\n",
    "# 'DWELTIME', \n",
    "# FIXME: need to get this from Elmer\n",
    "daysim_trip['DWELTIME'] = 10\n",
    "\n",
    "# 'PSGR_FLG',\n",
    "daysim_trip['PSGR_FLG'] = 2\n",
    "daysim_trip.loc[(daysim_trip['dorp'] == 1) & (daysim_trip['mode'].isin([3,4,5])), 'PSGR_FLG'] = 1\n",
    "\n",
    "# 'WHYFROM', \n",
    "daysim_trip['WHYFROM'] = daysim_trip['opurp'].map(purp_dict)\n",
    "\n",
    "# 'WHYTO', \n",
    "daysim_trip['WHYTO'] = daysim_trip['dpurp'].map(purp_dict)\n",
    "\n",
    "# 'VEHTYPE'\n",
    "# FIXEME: get this info from Elmer\n",
    "daysim_trip['VEHTYPE'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Workspace\\\\VisionEval\\\\psrc_scripts\\\\survey_data\\\\Dt_df.Rda'"
      ]
     },
     "execution_count": 711,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir + '\\\\Dt_df.Rda'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = daysim_trip[nhts_trip.columns]\n",
    "pyreadr.write_rdata(output_dir + '\\\\Dt_df.Rda', df, df_name=\"Dt_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NHTS survey files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = r'C:\\Workspace\\VisionEval_build\\VisionEval\\sources\\modules\\VE2001NHTS\\data-raw\\Veh_df.Rda'\n",
    "nhts_veh = pyreadr.read_r(fname)['Veh_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['HOUSEID', 'VEHID', 'BESTMILE', 'EIADMPG', 'GSCOST', 'VEHTYPE',\n",
       "       'VEHYEAR', 'VEHMILES'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nhts_veh.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "conn_string = \"DRIVER={ODBC Driver 17 for SQL Server}; SERVER=AWS-PROD-SQL\\Sockeye; DATABASE=Elmer; trusted_connection=yes\"\n",
    "sql_conn = pyodbc.connect(conn_string)\n",
    "df = pd.read_sql(sql='select * from HHSurvey.v_vehicles where survey_year=2017 or survey_year=2019', con=sql_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['HOUSEID']  = df['household_id'].astype('str')\n",
    "df['VEHID'] = df['vehnum'].copy()\n",
    "\n",
    "# BESTMILE\n",
    "# Best estimate of annual miles\n",
    "df['BESTMILE'] = 10000 # use average number, not sure how to get this info...\n",
    "\n",
    "# FIXME: look up this infro from some EPA database on mileage?\n",
    "# How did SANDAG do this?\n",
    "df['EIADMPG'] = 20\n",
    "\n",
    "# USing average here\n",
    "df['GSCOST'] = 350\n",
    "\n",
    "# FIXME: create a lookup for all the make and models\n",
    "df['VEHTYPE'] = 1\n",
    "# -8\tI don't know\t153\t0.1\n",
    "# 01\tAutomobile/Car/Station Wagon\t122,391\t47.8\n",
    "# 02\tVan (Mini/Cargo/Passenger)\t13,184\t5.1\n",
    "# 03\tSUV (Santa Fe, Tahoe, Jeep, etc.)\t60,353\t23.6\n",
    "# 04\tPickup Truck\t46,232\t18.1\n",
    "# 05\tOther Truck\t1,414\t0.6\n",
    "# 06\tRV (Recreational Vehicle)\t2,097\t0.8\n",
    "# 07\tMotorcycle/Motorbike\t9,283\t3.6\n",
    "# 97\tSomething Else\n",
    "# df.groupby(['make','model']).count().index\n",
    "\n",
    "df['VEHYEAR'] = df['year'].copy()\n",
    "\n",
    "# FIXME: get an average number of this?\n",
    "df['VEHMILES'] = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[nhts_veh.columns]\n",
    "pyreadr.write_rdata(output_dir + '\\\\Veh_df.Rda', df, df_name=\"Veh_df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Up\n",
    "Make sure all household have some tours or trips (?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load NHTS survey files\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ToursByHh_df'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-715-0457d7f6c350>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\ToursByHh_df.Rda'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf_tour\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpyreadr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_r\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'ToursByHh_df'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutput_dir\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'\\\\Per_df.Rda'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ToursByHh_df'"
     ]
    }
   ],
   "source": [
    "fname = output_dir + '\\\\Hh_df.Rda'\n",
    "df_hh = pyreadr.read_r(fname)['Hh_df']\n",
    "\n",
    "fname = output_dir + '\\\\ToursByHh_df.Rda'\n",
    "df_tour = pyreadr.read_r(fname)['ToursByHh_df']\n",
    "\n",
    "fname = output_dir + '\\\\Per_df.Rda'\n",
    "df_person = pyreadr.read_r(fname)['Per_df']\n",
    "\n",
    "df_hh = df_hh[df_hh['HOUSEID'].isin(df_tour['Houseid'])]\n",
    "df_person = df_person[df_person['HOUSEID'].isin(df_hh['HOUSEID'])]\n",
    "\n",
    "pyreadr.write_rdata(output_dir + '\\\\Hh_df.Rda', df_hh, df_name=\"Hh_df\")\n",
    "pyreadr.write_rdata(output_dir + '\\\\Per_df.Rda', df_hh, df_name=\"Per_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "864701c56f29bc7bdff9ffbb1f8a3bf6444c4b09036b469d0716607ad07d0991"
  },
  "kernelspec": {
   "display_name": "Python 3.7.10 ('summary')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
